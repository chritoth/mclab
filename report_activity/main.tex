\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{A Simple Activity Monitoring App\\
{\large Mobile Computing Lab - Summer Term 2018}
}

\author{\IEEEauthorblockN{Christian Toth}
\IEEEauthorblockA{
\textit{Graz University of Technology}\\
Graz, Austria \\
christian.toth@student.tugraz.at}
\and
\IEEEauthorblockN{Timur Cerimagic}
\IEEEauthorblockA{
\textit{Graz University of Technology}\\
Graz, Austria \\
t.cerimagic@student.tugraz.at}
}

\maketitle

\section{Task Description}
In order to get familiar with the sensing possibilities provided by smart phones the objective of this work was to develop a simple activity monitoring app running on Android. The desired app should eventually be able to recognize different user movement patterns like walking or jumping. Further requirements are to use appropriate sensor data provided by android and to classify the collected data utilizing a K-Nearest Neighbor (KNN)~\cite{knn1}\cite{knn2} algorithm. To realize the app we divided the project into the following tasks:
\begin{itemize}
\item Gathering activity (training) data using the sensors on an Android phone
\item Off-line feature engineering and model evaluation
\item Generation of an KNN training set
\item Implementing the model for Android
\item Implementing a simple GUI
\end{itemize}

Our resultant app collects sensor readings from the Androids linear acceleration sensor and extracts 48 frequency domain features every second. The resulting feature vector is classified using KNN over a training set of 172 training samples. We classify movement patterns into four different activities which are idle, jumping, walking and waving.

The remainder of this report is structured as follows. In Section~\ref{sec:features} we explain the feature engineering and extraction process. In Section ....

Specific implementations and details are going to be explained in the next chapter.

\section{Feature Engineering}
\label{sec:features}

Sensors and methods
If we start from the beginning of the previously mentioned road, first thing was gathering the sensor
data. For the jumping, walking, waving and idle activity differentiation, we used accelerometer;
particularly, linear accelerometer. Reason why we used linear, instead of regular accelerometer, lies in
fact that linear accelerometer excludes the gravity acceleration that eliminates ability to define phone’s
orientation, which in our case was positive feature. We needed the app which tracks movement
independent of phone’s orientation. For the training purposes, phone was held in the upright position.
We recorded activities one by one and stored them into the separate files, so that we can later add
classification field to the each (x,y,z) triplet. Data was randomly split into training set and test set in
80:20 proportion respectively. Initially, we created the model in python and after the success rate of
99\%, model was transferred to an android. For the feature extraction we used buffer of 48 x,y and z
value readings. Those values were run through the anti-aliasing filter for smoothing out, downsampled
to the 16 values and zeropaddded for the discrete Fourier transformation. We have applied FFT (Fast
Fourier Transform) for window creation of downsampled signal. Python model, as well as the android
model, were based on KNN classification algorithm [1][2]. Number K (k closest neighbors) was set to 21,
as we found it to be suitable in our case for higher hit probability. For KNN metrics we used Euclidian
distance, so every new point can be compared with the training data and classified into one of our 4
classes.


\section{Initial evaluation}

Initial evaluation indicates that mentioned methods and tools were fully applicable in terms of defined
problem. Results show around 99\% of accuracy rate, which is more than enough for the given
application field. We didn’t have any difficulties regarding the functionality of the system and all
activities were timely recognized. KNN algorithm with K of 21 neighbors showed good performance on
the given hardware architecture and considering that processing power of the smartphone was more
than enough for those kinds of computations, we were enabled to use power and processor hungry
mathematical operations without increasing the latency.



\begin{thebibliography}{00}
\bibitem{knn1} Fix, E., Hodges, J.L. Discriminatory analysis, nonparametric discrimination: Consistency properties. Technical Report 4, USAF School of Aviation Medicine, Randolph Field, Texas, 1951.
\bibitem{knn2} Cover, T.M., Hart, P.E. Nearest neighbor pattern classification. IEEE Trans. Inform. Theory, IT-13(1):21–27, 1967.
\end{thebibliography}


\end{document}
